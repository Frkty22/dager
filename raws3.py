import cv2
import numpy as np
import os
from ultralytics import YOLO
from typing import List, Dict, Tuple, Optional
import warnings

# ØªØ¬Ø§Ù‡Ù„ Ø§Ù„ØªØ­Ø°ÙŠØ±Ø§Øª ØºÙŠØ± Ø§Ù„Ø¶Ø±ÙˆØ±ÙŠØ©
warnings.filterwarnings("ignore")

class AdvancedTableExtractor:
    """
    ÙŠÙ‚ÙˆÙ… Ù‡Ø°Ø§ Ø§Ù„ÙƒÙ„Ø§Ø³ Ø§Ù„Ù…ØªÙ‚Ø¯Ù… Ø¨Ø§ÙƒØªØ´Ø§Ù ÙˆÙ‚Øµ Ø§Ù„Ø®Ù„Ø§ÙŠØ§ Ù…Ù† ØµÙˆØ± ØµÙÙˆÙ Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù†Ù…ÙˆØ°Ø¬ YOLO.
    ÙŠØªÙ…ÙŠØ² Ø¨Ø§Ù„Ø®ØµØ§Ø¦Øµ Ø§Ù„ØªØ§Ù„ÙŠØ©:
    - Ù…Ù†Ø·Ù‚ Ø¯ÙŠÙ†Ø§Ù…ÙŠÙƒÙŠ ÙŠØ¹ØªÙ…Ø¯ Ø¹Ù„Ù‰ Ù…ÙˆÙ‚Ø¹ "Ø§Ù„Ø§Ø³Ù…" ÙƒÙ†Ù‚Ø·Ø© Ù…Ø±Ø¬Ø¹ÙŠØ© (anchor).
    - Ø­Ø³Ø§Ø¨ Ø°ÙƒÙŠ Ù„Ù…ÙˆØ§Ù‚Ø¹ Ø§Ù„Ø®Ù„Ø§ÙŠØ§ Ø§Ù„Ù…ÙÙ‚ÙˆØ¯Ø© (Ø§Ù„ØªÙˆÙ‚ÙŠØ¹ ÙˆØ§Ù„Ø¯Ø±Ø¬Ø§Øª).
    - ØªØ±ØªÙŠØ¨ ØµØ­ÙŠØ­ Ù„Ù„Ø¯Ø±Ø¬Ø§Øª Ø­Ø³Ø¨ Ù…ÙˆÙ‚Ø¹Ù‡Ø§ Ø§Ù„Ø£ØµÙ„ÙŠ ÙÙŠ Ø§Ù„Ø¬Ø¯ÙˆÙ„.
    - ØªÙ†Ø¸ÙŠÙ Ø°ÙƒÙŠ Ù„Ù„Ø®Ù„Ø§ÙŠØ§ Ø§Ù„Ù…Ù‚ØªØµØ© Ù„Ø¥Ø²Ø§Ù„Ø© Ø®Ø·ÙˆØ· Ø§Ù„Ø¬Ø¯ÙˆÙ„ Ø§Ù„Ø£ÙÙ‚ÙŠØ©.
    """

    def __init__(self, model_path: str):
        """
        ØªÙ‡ÙŠØ¦Ø© Ø§Ù„ÙƒÙ„Ø§Ø³ ÙˆØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ YOLO.
        """
        self.model_path = model_path
        try:
            self.model = YOLO(model_path)
            print("âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ YOLO Ø¨Ù†Ø¬Ø§Ø­.")
        except Exception as e:
            raise Exception(f"âŒ ÙØ´Ù„ ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ YOLO: {e}")

        # Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ø§ÙƒØªØ´Ø§Ù
        self.detection_confidence = 0.9
        self.iou_threshold = 0.4
        # Ø§Ù„ØªØµÙ†ÙŠÙØ§Øª Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø© ÙÙ‚Ø·
        self.target_labels = ['dagrea1', 'dagrea2', 'dagrea3', 'dagrea4', 'name']

    def clean_cell_from_lines(self, cell_image: np.ndarray, threshold_ratio: float = 0.7) -> np.ndarray:
        """
        ØªÙ†Ø¸ÙŠÙ ØµÙˆØ±Ø© Ø§Ù„Ø®Ù„ÙŠØ© Ù…Ù† Ø§Ù„Ø®Ø·ÙˆØ· Ø§Ù„Ø£ÙÙ‚ÙŠØ© ÙÙŠ Ø§Ù„Ø£Ø¹Ù„Ù‰ ÙˆØ§Ù„Ø£Ø³ÙÙ„.
        """
        gray = cv2.cvtColor(cell_image, cv2.COLOR_BGR2GRAY)
        _, binary = cv2.threshold(gray, 200, 255, cv2.THRESH_BINARY_INV)
        
        h, w = binary.shape
        
        # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„Ø­Ø¯ Ø§Ù„Ø¹Ù„ÙˆÙŠ Ø§Ù„Ø¬Ø¯ÙŠØ¯
        y1_new = 0
        for y in range(h):
            row = binary[y, :]
            black_pixel_ratio = np.count_nonzero(row) / w
            if black_pixel_ratio < threshold_ratio:
                y1_new = y
                break
        
        # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„Ø­Ø¯ Ø§Ù„Ø³ÙÙ„ÙŠ Ø§Ù„Ø¬Ø¯ÙŠØ¯
        y2_new = h
        for y in range(h - 1, -1, -1):
            row = binary[y, :]
            black_pixel_ratio = np.count_nonzero(row) / w
            if black_pixel_ratio < threshold_ratio:
                y2_new = y + 1
                break
                
        # Ù‚Øµ Ø§Ù„ØµÙˆØ±Ø© Ø¨Ø§Ù„Ø¥Ø­Ø¯Ø§Ø«ÙŠØ§Øª Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø© Ø§Ù„Ù†Ø¸ÙŠÙØ©
        if y2_new > y1_new:
            return cell_image[y1_new:y2_new, :]
        else:
            return cell_image

    def calculate_cell_positions(self, name_box: Dict, detected_grade_boxes: List[Dict]) -> Dict:
        """
        Ø­Ø³Ø§Ø¨ Ù…ÙˆØ§Ù‚Ø¹ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø®Ù„Ø§ÙŠØ§ (Ø§Ù„Ù…ÙƒØªØ´ÙØ© ÙˆØ§Ù„Ù…ÙÙ‚ÙˆØ¯Ø©) Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ù…ÙˆÙ‚Ø¹ Ø§Ù„Ø§Ø³Ù… ÙˆØ§Ù„Ø¯Ø±Ø¬Ø§Øª Ø§Ù„Ù…ÙƒØªØ´ÙØ©.
        
        Args:
            name_box: Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ù…Ø±Ø¨Ø¹ Ø§Ù„Ø§Ø³Ù…
            detected_grade_boxes: Ù‚Ø§Ø¦Ù…Ø© Ø¨Ø§Ù„Ø¯Ø±Ø¬Ø§Øª Ø§Ù„Ù…ÙƒØªØ´ÙØ©
            
        Returns:
            Ù‚Ø§Ù…ÙˆØ³ ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ù…ÙˆØ§Ù‚Ø¹ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø®Ù„Ø§ÙŠØ§ Ù…Ø±ØªØ¨Ø©
        """
        name_x1, name_y1, name_x2, name_y2 = name_box['coordinates']
        name_width = name_x2 - name_x1
        name_height = name_y2 - name_y1
        
        # ØªØ±ØªÙŠØ¨ Ø§Ù„Ø¯Ø±Ø¬Ø§Øª Ø§Ù„Ù…ÙƒØªØ´ÙØ© Ù…Ù† Ø§Ù„ÙŠÙ…ÙŠÙ† Ø¥Ù„Ù‰ Ø§Ù„ÙŠØ³Ø§Ø±
        detected_grade_boxes.sort(key=lambda x: x['center_x'], reverse=True)
        
        # Ø­Ø³Ø§Ø¨ Ù…ØªÙˆØ³Ø· Ø¹Ø±Ø¶ ÙˆØ§Ø±ØªÙØ§Ø¹ Ù…Ø±Ø¨Ø¹Ø§Øª Ø§Ù„Ø¯Ø±Ø¬Ø§Øª
        if detected_grade_boxes:
            grade_widths = []
            grade_heights = []
            for grade_box in detected_grade_boxes:
                gx1, gy1, gx2, gy2 = grade_box['coordinates']
                grade_widths.append(gx2 - gx1)
                grade_heights.append(gy2 - gy1)
            
            avg_grade_width = int(np.mean(grade_widths))
            avg_grade_height = int(np.mean(grade_heights))
        else:
            # ÙÙŠ Ø­Ø§Ù„Ø© Ø¹Ø¯Ù… ÙˆØ¬ÙˆØ¯ Ø¯Ø±Ø¬Ø§Øª Ù…ÙƒØªØ´ÙØ©ØŒ Ù†Ù‚Ø¯Ø± Ø§Ù„Ø­Ø¬Ù…
            avg_grade_width = name_width // 4  # ØªÙ‚Ø¯ÙŠØ± Ø£Ù† Ø¹Ø±Ø¶ Ø§Ù„Ø¯Ø±Ø¬Ø© Ø±Ø¨Ø¹ Ø¹Ø±Ø¶ Ø§Ù„Ø§Ø³Ù…
            avg_grade_height = name_height
        
        # Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…ÙˆØ§Ù‚Ø¹ Ø§Ù„Ù†Ø¸Ø±ÙŠØ© Ù„Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø®Ù„Ø§ÙŠØ§ (5 Ø®Ù„Ø§ÙŠØ§: ØªÙˆÙ‚ÙŠØ¹ + 4 Ø¯Ø±Ø¬Ø§Øª)
        theoretical_positions = {}
        
        # 1. Ø®Ù„ÙŠØ© Ø§Ù„ØªÙˆÙ‚ÙŠØ¹ - Ø¨ÙŠÙ† Ø§Ù„Ø§Ø³Ù… ÙˆØ§Ù„Ø¯Ø±Ø¬Ø© Ø§Ù„Ø£ÙˆÙ„Ù‰
        signature_x2 = name_x1
        signature_x1 = signature_x2 - avg_grade_width
        theoretical_positions['signature'] = {
            'coordinates': (signature_x1, name_y1, signature_x2, name_y2),
            'confidence': 0.0,  # Ù…Ø³ØªÙ†ØªØ¬Ø©
            'cell_type': 'signature'
        }
        
        # 2. Ø§Ù„Ø¯Ø±Ø¬Ø§Øª Ø§Ù„Ø£Ø±Ø¨Ø¹
        current_x = signature_x1
        for i in range(4):
            grade_x2 = current_x
            grade_x1 = grade_x2 - avg_grade_width
            theoretical_positions[f'grade_{i+1}'] = {
                'coordinates': (grade_x1, name_y1, grade_x2, name_y2),
                'confidence': 0.0,  # Ø³ÙŠØªÙ… ØªØ­Ø¯ÙŠØ«Ù‡Ø§ Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ù…ÙƒØªØ´ÙØ©
                'cell_type': f'grade_{i+1}'
            }
            current_x = grade_x1
        
        # 3. Ø±Ø¨Ø· Ø§Ù„Ø¯Ø±Ø¬Ø§Øª Ø§Ù„Ù…ÙƒØªØ´ÙØ© Ø¨Ù…ÙˆØ§Ù‚Ø¹Ù‡Ø§ Ø§Ù„Ù†Ø¸Ø±ÙŠØ©
        for detected_box in detected_grade_boxes:
            detected_center_x = detected_box['center_x']
            best_match = None
            min_distance = float('inf')
            
            # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø£Ù‚Ø±Ø¨ Ù…ÙˆÙ‚Ø¹ Ù†Ø¸Ø±ÙŠ
            for grade_key in ['grade_1', 'grade_2', 'grade_3', 'grade_4']:
                theoretical_center_x = (theoretical_positions[grade_key]['coordinates'][0] + 
                                      theoretical_positions[grade_key]['coordinates'][2]) // 2
                distance = abs(detected_center_x - theoretical_center_x)
                
                if distance < min_distance:
                    min_distance = distance
                    best_match = grade_key
            
            # ØªØ­Ø¯ÙŠØ« Ø§Ù„Ù…ÙˆÙ‚Ø¹ Ø§Ù„Ù†Ø¸Ø±ÙŠ Ø¨Ø§Ù„Ù…ÙˆÙ‚Ø¹ Ø§Ù„Ù…ÙƒØªØ´Ù
            if best_match:
                theoretical_positions[best_match]['coordinates'] = detected_box['coordinates']
                theoretical_positions[best_match]['confidence'] = detected_box['confidence']
        
        return theoretical_positions

    def _crop_and_save_cell(self, original_image: np.ndarray, box_info: Dict, crops_dir: str, 
                           filename_prefix: str, index: int):
        """
        Ù‚Øµ Ø®Ù„ÙŠØ© ÙˆØ§Ø­Ø¯Ø©ØŒ ØªÙ†Ø¸ÙŠÙÙ‡Ø§ØŒ ÙˆØ­ÙØ¸Ù‡Ø§.
        """
        x1, y1, x2, y2 = box_info['coordinates']
        
        # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØµØ­Ø© Ø§Ù„Ø¥Ø­Ø¯Ø§Ø«ÙŠØ§Øª
        if x2 > x1 and y2 > y1 and x1 >= 0 and y1 >= 0:
            # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø£Ù† Ø§Ù„Ø¥Ø­Ø¯Ø§Ø«ÙŠØ§Øª Ù„Ø§ ØªØªØ¬Ø§ÙˆØ² Ø­Ø¯ÙˆØ¯ Ø§Ù„ØµÙˆØ±Ø©
            h, w = original_image.shape[:2]
            x1, y1, x2, y2 = max(0, x1), max(0, y1), min(w, x2), min(h, y2)
            
            # Ù‚Øµ Ø§Ù„Ø®Ù„ÙŠØ©
            cropped_cell = original_image[y1:y2, x1:x2]
            
            # ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø®Ù„ÙŠØ© Ù…Ù† Ø§Ù„Ø®Ø·ÙˆØ·
            cleaned_cell = self.clean_cell_from_lines(cropped_cell)
            
            # Ø­ÙØ¸ Ø§Ù„Ø®Ù„ÙŠØ© Ø§Ù„Ù†Ø¸ÙŠÙØ©
            confidence_str = f"{box_info['confidence']:.2f}".replace('.', '_')
            crop_filename = f"{filename_prefix}_{index}_{confidence_str}.png"
            crop_save_path = os.path.join(crops_dir, crop_filename)
            
            cv2.imwrite(crop_save_path, cleaned_cell)
            
            # Ø·Ø¨Ø§Ø¹Ø© Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ø®Ù„ÙŠØ©
            cell_status = "Ù…ÙƒØªØ´ÙØ©" if box_info['confidence'] > 0 else "Ù…Ø³ØªÙ†ØªØ¬Ø©"
            print(f"   ğŸ’¾ ØªÙ… Ø­ÙØ¸ {filename_prefix} ({cell_status}): {crop_filename}")
        else:
            print(f"âš ï¸ ØªÙ… ØªØ¬Ø§Ù‡Ù„ '{filename_prefix}' Ù„Ø£Ù† Ø£Ø¨Ø¹Ø§Ø¯Ù‡Ø§ ØºÙŠØ± ØµØ§Ù„Ø­Ø©")

    def process_image(self, image_path: str, output_dir: str):
        """
        Ù…Ø¹Ø§Ù„Ø¬Ø© ØµÙˆØ±Ø© ÙˆØ§Ø­Ø¯Ø©: Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø¯Ø±Ø¬Ø§Øª Ø§Ù„Ø£Ø±Ø¨Ø¹ ÙˆØ§Ù„Ø§Ø³Ù… Ù…Ø¨Ø§Ø´Ø±Ø© Ù…Ù† Ù†Ù…ÙˆØ°Ø¬ YOLO Ø§Ù„Ù…Ø¯Ø±Ø¨.
        """
        if not os.path.exists(image_path):
            print(f"âŒ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø§Ù„ØµÙˆØ±Ø©: {image_path}")
            return

        print(f"\n--- ğŸš€ Ø¨Ø¯Ø¡ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…ØªÙ‚Ø¯Ù…Ø© Ù„Ù„ØµÙˆØ±Ø©: {os.path.basename(image_path)} ---")
        image_name = os.path.splitext(os.path.basename(image_path))[0]
        results_dir = os.path.join(output_dir, image_name)
        os.makedirs(results_dir, exist_ok=True)

        # ØªÙ†ÙÙŠØ° Ù†Ù…ÙˆØ°Ø¬ YOLO
        try:
            results = self.model.predict(
                source=image_path,
                conf=self.detection_confidence,
                iou=self.iou_threshold,
                verbose=False
            )
        except Exception as e:
            print(f"âŒ Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„ØªÙ†Ø¨Ø¤: {e}")
            return

        result = results[0]
        if len(result.boxes) == 0:
            print("âš ï¸ Ù„Ù… ÙŠØªÙ… Ø§ÙƒØªØ´Ø§Ù Ø£ÙŠ Ø®Ù„Ø§ÙŠØ§ ÙÙŠ Ø§Ù„ØµÙˆØ±Ø©.")
            return

        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ ÙÙ‚Ø· Ø§Ù„Ø®Ù„Ø§ÙŠØ§ Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø© (Ø§Ù„Ø¯Ø±Ø¬Ø§Øª Ø§Ù„Ø£Ø±Ø¨Ø¹ ÙˆØ§Ù„Ø§Ø³Ù…)
        all_boxes = []
        for i, box in enumerate(result.boxes):
            label = self.model.names[int(box.cls[0])]
            if label not in self.target_labels:
                continue
            x1, y1, x2, y2 = [int(c) for c in box.xyxy[0].tolist()]
            all_boxes.append({
                'index': i,
                'label': label,
                'confidence': float(box.conf[0]),
                'coordinates': (x1, y1, x2, y2),
                'center_x': (x1 + x2) // 2
            })

        # ØªØ±ØªÙŠØ¨ Ø§Ù„Ø®Ù„Ø§ÙŠØ§: Ø§Ù„Ø§Ø³Ù… Ø«Ù… Ø§Ù„Ø¯Ø±Ø¬Ø§Øª Ø­Ø³Ø¨ Ø§Ù„ØªØ±ØªÙŠØ¨
        crops_dir = os.path.join(results_dir, "cleaned_cells")
        os.makedirs(crops_dir, exist_ok=True)
        original_image = result.orig_img

        # Ø­ÙØ¸ Ø®Ù„ÙŠØ© Ø§Ù„Ø§Ø³Ù…
        name_boxes = [b for b in all_boxes if b['label'] == 'name']
        if name_boxes:
            name_box = max(name_boxes, key=lambda b: b['confidence'])
            self._crop_and_save_cell(original_image, name_box, crops_dir, "name", 1)
        else:
            print("âš ï¸ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø®Ø§Ù†Ø© Ø§Ù„Ø§Ø³Ù….")

        # Ø­ÙØ¸ Ø§Ù„Ø¯Ø±Ø¬Ø§Øª Ø§Ù„Ø£Ø±Ø¨Ø¹ Ø­Ø³Ø¨ Ø§Ù„ØªØ±ØªÙŠØ¨ (ØªØºÙŠÙŠØ± Ø§Ù„Ø§Ø³Ù… Ø¥Ù„Ù‰ grade_1, grade_2, ...)
        for idx, grade_label in enumerate(['dagrea1', 'dagrea2', 'dagrea3', 'dagrea4'], start=1):
            grade_boxes = [b for b in all_boxes if b['label'] == grade_label]
            if grade_boxes:
                grade_box = max(grade_boxes, key=lambda b: b['confidence'])
                # Ø­ÙØ¸ Ø¨Ø§Ø³Ù… grade_1, grade_2, ...
                self._crop_and_save_cell(original_image, grade_box, crops_dir, f"grade_{idx}", idx)
            else:
                print(f"âš ï¸ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø®Ø§Ù†Ø© {grade_label}.")

        print(f"âœ… Ø§Ù†ØªÙ‡Øª Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©. ØªÙ… Ø­ÙØ¸ {len(os.listdir(crops_dir))} Ø®Ù„ÙŠØ© Ù†Ø¸ÙŠÙØ© ÙÙŠ: {crops_dir}")

        # Ø­ÙØ¸ Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ø£ØµÙ„ÙŠØ© Ù…Ø¹ Ø§Ù„Ù…Ø±Ø¨Ø¹Ø§Øª Ù„Ù„ØªØ­Ù‚Ù‚
        annotated_image = result.plot()
        annotated_image_path = os.path.join(results_dir, f"{image_name}_annotated.png")
        cv2.imwrite(annotated_image_path, annotated_image)

    def process_batch(self, input_folder: str, output_folder: str):
        """
        Ù…Ø¹Ø§Ù„Ø¬Ø© Ø¬Ù…ÙŠØ¹ Ø§Ù„ØµÙˆØ± ÙÙŠ Ù…Ø¬Ù„Ø¯ Ø§Ù„Ø¥Ø¯Ø®Ø§Ù„.
        """
        if not os.path.isdir(input_folder):
            print(f"âŒ Ù…Ø¬Ù„Ø¯ Ø§Ù„Ø¥Ø¯Ø®Ø§Ù„ '{input_folder}' ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯.")
            return
            
        os.makedirs(output_folder, exist_ok=True)
        
        image_files = [f for f in os.listdir(input_folder) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]
        if not image_files:
            print(f"âŒ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø£ÙŠ ØµÙˆØ± ÙÙŠ Ø§Ù„Ù…Ø¬Ù„Ø¯: {input_folder}")
            return
            
        print(f"\n" + "="*60)
        print(f"ğŸ” ØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ {len(image_files)} ØµÙˆØ±Ø© Ù„Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© ÙÙŠ '{input_folder}'.")
        print(f"ğŸ“‚ Ø³ÙŠØªÙ… Ø­ÙØ¸ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ ÙÙŠ '{output_folder}'.")
        print("="*60)

        for image_file in image_files:
            image_path = os.path.join(input_folder, image_file)
            self.process_image(image_path, output_folder)
            
        print("\n" + "="*60)
        print("ğŸ‰ ØªÙ…Øª Ù…Ø¹Ø§Ù„Ø¬Ø© Ø¬Ù…ÙŠØ¹ Ø§Ù„ØµÙˆØ± Ø¨Ù†Ø¬Ø§Ø­!")
        print("="*60)


def main():
    """
    Ø§Ù„Ø¯Ø§Ù„Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© Ù„ØªØ´ØºÙŠÙ„ Ø§Ù„ÙƒÙˆØ¯.
    """
    # --- Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… ---
    model_path = r'lasst.pt'  # â—ï¸ Ù…Ø³Ø§Ø± Ù†Ù…ÙˆØ°Ø¬ YOLO
    input_folder = r'output_pipeline\3_extracted_rows'                       # ğŸ“‚ Ù…Ø¬Ù„Ø¯ Ø§Ù„ØµÙˆØ± Ø§Ù„Ù…Ø¯Ø®Ù„Ø©
    output_folder = 'advanced_extraction_results'     # ğŸ¯ Ù…Ø¬Ù„Ø¯ Ø­ÙØ¸ Ø§Ù„Ù†ØªØ§Ø¦Ø¬

    try:
        extractor = AdvancedTableExtractor(model_path=model_path)
        extractor.process_batch(input_folder, output_folder)

    except Exception as e:
        print(f"âŒ Ø­Ø¯Ø« Ø®Ø·Ø£ ÙØ§Ø¯Ø­ ÙÙŠ Ø§Ù„Ø¨Ø±Ù†Ø§Ù…Ø¬: {e}")

if __name__ == "__main__":
    main()